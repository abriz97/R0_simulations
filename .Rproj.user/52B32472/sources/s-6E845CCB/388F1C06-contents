
# extract actual R0 values used in simualtion
true <- simulations$pars






true <- read.csv("True_R0.csv")
true$trueR <- true$R0
df_P$data <- "Poisson noise"
df_n$data <- "No noise"
df_NB$data <- "NegBinomial noise"
results <- rbind(df_n, df_P, df_NB)
results <- merge(results, true, by="sim")


#=== Remove sections with missing estimates
# determine missing estimates sections
missing <- data.frame(sim=NA, weeks=NA)
count <- 0
for(i in 1:length(results$sim)){
  if(is.na(results$R0.x[i])==TRUE){
    count <- count+1
    missing[count, ] <- c(results$sim[i], results$Nweeks[i])
  }
}

# Loop to remove sections with missing estimates (for systematic comparison)
mi <- unique(missing$sim) # simulations with missing estimates
for(i in 1:length(mi)){
  mi_sim <- subset(missing, missing$sim==mi[i])
  for(j in unique(mi_sim$weeks)){
    results <- results[(results$sim!=mi[i] | results$Nweeks!=j),]
    
  }
}


#===== Assess Performance =====#

# root mean squared error
rmse <- function(error){
  round(sqrt(mean(error^2)), digits=2)
}

# mean absolute error
mae <- function(error){
  round(mean(abs(error)), digits=2)
}

# calculate performance metrics for each method in the early stages of the epidemic
results <- subset(results, results$Nweeks<16)
methods <- as.vector(unique(results$method))
datatype <- c("No noise", "Poisson noise", "NegBinomial noise")
nweek <- c(6,9,12,15)

# bias
results$bias <- results$R0.x - results$trueR

# width of CI
results$ciW <- results$CI_U - results$CI_L

# coverage by 95% CI's
results$covYN <- NA
for(i in 1:nrow(results)){
  if(results$CI_U[i]>=results$trueR[i] & results$CI_L[i]<=results$trueR[i]){
    results$covYN[i] <- 1
  }else{
    results$covYN[i] <- 0
  }
}

# dataframe for performance summary results
perf <- data.frame(data=NA, sections=NA, method=NA, pears=NA, spear=NA,
                   slope=NA, r2=NA, rmse=NA, mae=NA, ciW=NA, cov=NA, bias=NA)
count <- 0
for(k in unique(datatype)){
  
  d <- subset(results, results$data==k) # for each level of noise
  
  for(i in 1:4){
    
    n_i <- subset(d, d$Nweeks==nweek[i]) # for each section
    
    for(j in 1:4){
      
      m_i <- subset(n_i, n_i$method==methods[j]) # for each method
      
      # calculate the slope
      lin_mod <- lm(R0.x ~ trueR, data=m_i)
      r2 <- format(round(summary(lin_mod)$r.squared, digits=2))
      m <- format(round(coef(lin_mod)[2], digits=2))
      
      # pearsons & spearmans correlation coefficient
      pears <- format(round(cor(m_i$trueR, m_i$R0.x, method="pearson"), digits=2))
      spear <- format(round(cor(m_i$trueR, m_i$R0.x, method="spearman"), digits=2))
      
      # error 
      errors <- m_i$R0.y - m_i$R0.x
      
      # store results
      count <- count+1
      perf[count, ] <- c(k, nweek[i], methods[j], pears, spear, m, r2, rmse(errors), mae(errors),
                         mean(m_i$ciW), sum(m_i$covYN)/nrow(m_i), mean(m_i$bias))
      
    }
  }
}


#===== Plots to compare performance =====#

# function for plotting
plotfunc <- function(results){
  p <- ggplot(data=results) + geom_point(aes(x=trueR, y=R0.x, colour=method), alpha=0.5)+
    geom_line(aes(x=trueR, y=trueR))+ geom_smooth(aes(x=trueR, y=R0.x, colour=method), method="lm", se=FALSE)+
    geom_linerange(aes(x=trueR, ymin=CI_L, ymax=CI_U, colour=method))+
    ylab("Estimated R")+ xlab("True R")+ facet_grid(Nweeks~method, scales="free_y")+
    theme_grey()+ theme(legend.position="none")+ 
    scale_color_manual(values=c("royalblue1", "violetred1", "lawngreen", "orange1"))
  return(p)
}

results$Nweeks <- as.factor(results$Nweeks)
results$method <- factor(results$method, levels=c("ExpLin", "ExpPois", "EpiEstim", "WP"))


# check for each data type
simResults <- subset(results, results$data=="No noise")
simResults_P <- subset(results, results$data=="Poisson noise")
simResults_NB <- subset(results, results$data=="NegBinomial noise")

# plot 
p_nonoise <- plotfunc(simResults)
p_Pnoise <- plotfunc(simResults_P)
p_NBnoise <- plotfunc(simResults_NB)



#===== Compare performance metrics by data type and epidemic stage =====#

perf$sections <- factor(perf$sections, levels=c(6,9,12,15))
perf$method <- factor(perf$method, levels=c("ExpLin", "ExpPois", "EpiEstim", "WP"))
perf$data <- factor(perf$data, levels=c("No noise", "Poisson noise", "NegBinomial noise"))

# convert to long format for plotting
library(dplyr)
perf2 <- bind_rows(replicate(8, perf[ ,1:3], simplify=FALSE))
perf2$est <- c(rep("Slope", 48), rep("PCC", 48), rep("SCC", 48), rep("RMSE", 48),
               rep("MAE", 48), rep("95%CI width", 48), rep("Coverage", 48), rep("Bias", 48))
perf2$estn <- c(perf$slope, perf$pears, perf$spear, perf$rmse, perf$mae, 
                format(round(as.numeric(perf$ciW), digits=2)), 
                format(round(as.numeric(perf$cov), digits=2)),
                format(round(as.numeric(perf$bias), digits=2)))


perf2$estn <- as.numeric(perf2$estn)
# which metrics to display
metricwants <- c("PCC", "RMSE", "95%CI width", "Coverage", "Bias")
p2 <- perf2[(perf2$est %in% metricwants), ]
p2$est <- factor(p2$est, levels=c("Bias", "Coverage", "95%CI width", "PCC", "RMSE")) # order

# plot performance metrics
PerfPlot <- ggplot(p2)+ geom_point(aes(x=sections, y=estn, group=method, colour=method))+
  geom_line(aes(x=sections, y=estn, group=method, colour=method))+ facet_grid(est~data, scales="free_y")+
  scale_color_manual(values=c("royalblue1", "violetred1", "lawngreen", "orange1"))+
  theme_grey()+ xlab("Number of weeks")+ ylab("Values of performance metrics")+
  theme(text=element_text(size=12))
PerfPlot



